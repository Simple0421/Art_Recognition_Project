import torch
import torch.nn as nn
import torch.optim as optim
import os
import sys
from tqdm import tqdm  # é€²åº¦æ¢é¡¯ç¤º

# å°‡ç›®å‰æª”æ¡ˆæ‰€åœ¨çš„ä¸Šä¸€å±¤ç›®éŒ„ (å°ˆæ¡ˆæ ¹ç›®éŒ„) åŠ å…¥ Python æœå°‹è·¯å¾‘
# é€™æ¨£ Python æ‰çœ‹å¾—åˆ°å¤–é¢çš„ config.py
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# åŒ¯å…¥æˆ‘å€‘å¯«å¥½çš„æ¨¡çµ„
import config
from dataset import get_dataloaders
from model import get_model

def train_one_epoch(model, loader, criterion, optimizer, device):
    model.train() # è¨­å®šç‚ºè¨“ç·´æ¨¡å¼
    running_loss = 0.0
    correct = 0
    total = 0
    
    # tqdm åªæ˜¯ç‚ºäº†è®“ Terminal æœ‰æ¼‚äº®çš„é€²åº¦æ¢
    loop = tqdm(loader, desc="Training", leave=False)
    
    for images, labels in loop:
        images, labels = images.to(device), labels.to(device)
        
        # 1. æ¸…ç©ºæ¢¯åº¦
        optimizer.zero_grad()
        
        # 2. å‰å‘å‚³æ’­ (Forward)
        outputs = model(images)
        
        # 3. è¨ˆç®— Loss
        loss = criterion(outputs, labels)
        
        # 4. åå‘å‚³æ’­ (Backward)
        loss.backward()
        
        # 5. æ›´æ–°åƒæ•¸
        optimizer.step()
        
        # çµ±è¨ˆæ•¸æ“š
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
        
        # æ›´æ–°é€²åº¦æ¢è³‡è¨Š
        loop.set_postfix(loss=loss.item())
        
    epoch_loss = running_loss / len(loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc

def validate(model, loader, criterion, device):
    model.eval() # è¨­å®šç‚ºè©•ä¼°æ¨¡å¼ (ä¸æ›´æ–°åƒæ•¸ã€ä¸Dropout)
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad(): # é©—è­‰æ™‚ä¸éœ€è¦è¨ˆç®—æ¢¯åº¦ï¼Œç¯€çœè¨˜æ†¶é«”
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
    epoch_loss = running_loss / len(loader)
    epoch_acc = 100. * correct / total
    return epoch_loss, epoch_acc

def main():
    # 1. æº–å‚™è³‡æ–™
    print("æ­£åœ¨è®€å–è³‡æ–™...")
    train_loader, val_loader, class_names = get_dataloaders(
        config.DATA_DIR, 
        batch_size=config.BATCH_SIZE,
        val_split=config.VAL_SPLIT
    )
    
    num_classes = len(class_names)
    print(f"é¡åˆ¥æ•¸é‡: {num_classes}")
    
    # 2. æº–å‚™æ¨¡å‹ (åŠ å…¥ tune_backend=True é–‹å•Ÿå¾®èª¿æ¨¡å¼)
    print(f"æ­£åœ¨å»ºç«‹æ¨¡å‹: {config.MODEL_NAME} (å¾®èª¿æ¨¡å¼)...")
    device = torch.device(config.DEVICE)
    
    # å‚³å…¥æ¨¡å‹åç¨±
    model = get_model(num_classes, model_name=config.MODEL_NAME, tune_backend=True).to(device)
    
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    
    # --- è‡ªå‹•åŒ– Optimizer è¨­å®š ---
    # å› ç‚ºä¸åŒæ¨¡å‹çš„å±¤åç¨±ä¸ä¸€æ¨£ (layer3 vs features.7 vs denseblock4)
    # æˆ‘å€‘æ”¹ç”¨ "éæ¿¾æ³•"ï¼šåªè¦æ˜¯ requires_grad=True çš„åƒæ•¸ï¼Œå°±ä¸Ÿé€²å»ç·´
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    
    optimizer = optim.Adam(trainable_params, lr=config.LEARNING_RATE, weight_decay=1e-4)
    
    # (é¸ç”¨) åŠ å…¥å­¸ç¿’ç‡æ’ç¨‹å™¨ï¼šè®“ LR éš¨è‘— Epoch æ…¢æ…¢è®Šå°
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.NUM_EPOCHS)

    # 4. é–‹å§‹è¨“ç·´
    print(f"é–‹å§‹è¨“ç·´ï¼Œå…± {config.NUM_EPOCHS} å€‹ Epochs...")
    best_acc = 0.0
    
    for epoch in range(config.NUM_EPOCHS):
        # è¨“ç·´éšæ®µ
        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)
        
        # é©—è­‰éšæ®µ
        val_loss, val_acc = validate(model, val_loader, criterion, device)
        
        scheduler.step() # <--- æ¯å€‹ Epoch çµæŸå¾Œæ›´æ–°å­¸ç¿’ç‡
        
        print(f"Epoch [{epoch+1}/{config.NUM_EPOCHS}] "
              f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | "
              f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_acc:
            best_acc = val_acc
            if not os.path.exists(config.CHECKPOINT_DIR):
                os.makedirs(config.CHECKPOINT_DIR)
            torch.save(model.state_dict(), config.MODEL_SAVE_PATH)
            print(f"ğŸš€ ç™¼ç¾æœ€ä½³æ¨¡å‹ (Acc: {best_acc:.2f}%)ï¼Œå·²å„²å­˜è‡³ {config.MODEL_SAVE_PATH}")
            
    print("è¨“ç·´çµæŸï¼")

if __name__ == "__main__":
    main()