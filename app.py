import streamlit as st
import torch
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import os
import pandas as pd
import altair as alt
import config
import numpy as np

# åŒ¯å…¥ä½ çš„æœ¬åœ°æ¨¡çµ„
from src import model
from src.dataset import get_dataloaders
# --- æ–°å¢æ¨¡çµ„ ---
from src.feature_extractor import FeatureExtractor
from src.image_search import ImageSearcher

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="è—è¡“åç•«è¾¨è­˜ç³»çµ±",
    page_icon="ğŸ¨",
    layout="wide"
)

st.title("ğŸ¨ è—è¡“åç•«è¾¨è­˜ç³»çµ±")
st.markdown("### AI è—è¡“é‘‘è³èˆ‡éˆæ„Ÿæœå°‹å¼•æ“")

# --- 2. ç³»çµ±è¨­å®šèˆ‡å·¥å…·å‡½æ•¸ ---
DEVICE = torch.device(config.DEVICE)

# å®šç¾©é è™•ç† (å¿…é ˆè·Ÿé©—è­‰é›†çš„ä¸€æ¨¡ä¸€æ¨£)
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

@st.cache_resource
def load_class_names():
    """è¼‰å…¥é¡åˆ¥åç¨± (åªåŸ·è¡Œä¸€æ¬¡)"""
    try:
        _, _, classes = get_dataloaders(config.DATA_DIR, batch_size=1)
        return classes
    except Exception as e:
        st.error(f"ç„¡æ³•è®€å–é¡åˆ¥è³‡è¨Š: {e}")
        return []

@st.cache_resource
def load_single_model(num_classes):
    """è¼‰å…¥å–®ä¸€ ResNet50 æ¨¡å‹"""
    try:
        net = model.get_model(num_classes, model_name='resnet50', tune_backend=False)
        weight_path = './checkpoints/resnet50_best.pth'
        net.load_state_dict(torch.load(weight_path, map_location=DEVICE))
        net.to(DEVICE)
        net.eval()
        return net
    except FileNotFoundError:
        st.error("æ‰¾ä¸åˆ° checkpoints/resnet50_best.pthï¼Œè«‹ç¢ºèªæª”æ¡ˆä½ç½®ã€‚")
        return None

@st.cache_resource
def load_ensemble_models(num_classes):
    """è¼‰å…¥ä¸‰åˆä¸€é›†æˆæ¨¡å‹"""
    models = []
    configs = [
        ('resnet50', './checkpoints/resnet50_best.pth'),
        ('densenet121', './checkpoints/densenet121_best.pth'),
        ('efficientnet_b0', './checkpoints/efficientnet_b0_best.pth')
    ]
    
    for name, path in configs:
        try:
            net = model.get_model(num_classes, model_name=name, tune_backend=False)
            net.load_state_dict(torch.load(path, map_location=DEVICE))
            net.to(DEVICE)
            net.eval()
            models.append(net)
        except FileNotFoundError:
            st.warning(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° {path}ï¼Œé›†æˆæ¨¡å‹å°‡ç¼ºå°‘æ­¤æˆå“¡ã€‚")
            
    return models

# --- æ–°å¢ï¼šè¼‰å…¥ç‰¹å¾µæå–å™¨èˆ‡æœå°‹å¼•æ“ ---
@st.cache_resource
def load_retrieval_system():
    """è¼‰å…¥ä»¥åœ–æœåœ–ç³»çµ± (Feature Extractor + FAISS Searcher)"""
    # 1. ç‰¹å¾µæå–å™¨ (ä½¿ç”¨ ResNet50)
    # æ³¨æ„ï¼šé€™è£¡å»ºè­°ç”¨è·Ÿè¨“ç·´æ™‚ä¸€æ¨£çš„æ¬Šé‡ï¼Œæ•ˆæœæœ€å¥½
    try:
        extractor = FeatureExtractor(
            model_name='resnet50', 
            weight_path='./checkpoints/resnet50_best.pth'
        )
    except Exception as e:
        st.error(f"ç„¡æ³•è¼‰å…¥ç‰¹å¾µæå–å™¨: {e}")
        return None, None

    # 2. æœå°‹å¼•æ“ (è®€å– .npy)
    try:
        searcher = ImageSearcher(
            feature_path='data/processed/wikiart_features.npy',
            path_file_path='data/processed/wikiart_paths.npy'
        )
        return extractor, searcher
    except Exception as e:
        st.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥æœå°‹è³‡æ–™åº« (è‹¥æ˜¯ç¬¬ä¸€æ¬¡åŸ·è¡Œï¼Œè«‹å…ˆè·‘ build_features.py): {e}")
        return extractor, None

def predict_single(net, img_tensor):
    """å–®ä¸€æ¨¡å‹é æ¸¬"""
    with torch.no_grad():
        outputs = net(img_tensor)
        probs = F.softmax(outputs, dim=1)
    return probs[0]

def predict_ensemble(models, img_tensor):
    """é›†æˆæ¨¡å‹é æ¸¬ (å¹³å‡æ³•)"""
    total_probs = None
    with torch.no_grad():
        for net in models:
            outputs = net(img_tensor)
            probs = F.softmax(outputs, dim=1)
            
            if total_probs is None:
                total_probs = probs
            else:
                total_probs += probs
    
    avg_probs = total_probs / len(models)
    return avg_probs[0]

# --- 3. å´é‚Šæ¬„è¨­å®š ---
st.sidebar.header("âš™ï¸ è¨­å®šé¢æ¿")

# é¸æ“‡æ¨¡å¼ (åªå½±éŸ¿ Tab 1)
model_mode = st.sidebar.radio(
    "é¸æ“‡è¾¨è­˜æ¨¡å‹ï¼š",
    ("å–®ä¸€æ¨¡å‹ (ResNet50)", "ä¸‰åˆä¸€é›†æˆ (Ensemble)")
)

st.sidebar.info(
    """
    **åŠŸèƒ½èªªæ˜ï¼š**
    1. **ç•«å®¶è¾¨è­˜**ï¼šåˆ†è¾¨é€™å¹…ç•«æ˜¯èª°ç•«çš„ (50ä½å¤§å¸«)ã€‚å¯é¸æ“‡å–®ä¸€æ¨¡å‹ (ResNet50), ä¸‰åˆä¸€é›†æˆ (Ensemble)ã€‚
    2. **ä»¥åœ–æœåœ–**ï¼šåœ¨ 8 è¬å¼µ WikiArt è³‡æ–™åº«ä¸­ï¼Œå°‹æ‰¾é¢¨æ ¼ç›¸ä¼¼çš„ç•«ä½œã€‚ä½¿ç”¨å–®ä¸€æ¨¡å‹ (ResNet50)ã€‚
    """
)

# --- 4. ä¸»ç¨‹å¼é‚è¼¯ ---

# A. åˆå§‹åŒ–æ‰€æœ‰ç³»çµ±
class_names = load_class_names()
num_classes = len(class_names)

# è¼‰å…¥è¾¨è­˜æ¨¡å‹
if num_classes > 0:
    if model_mode == "å–®ä¸€æ¨¡å‹ (ResNet50)":
        active_model = load_single_model(num_classes)
        ensemble_models = None
    else:
        active_model = None
        ensemble_models = load_ensemble_models(num_classes)
else:
    active_model = None
    ensemble_models = None

# è¼‰å…¥æœåœ–ç³»çµ±
feature_extractor, image_searcher = load_retrieval_system()

# B. å…¨åŸŸåœ–ç‰‡ä¸Šå‚³ (æ”¾åœ¨ Tab ä¹‹ä¸Š)
st.markdown("---")
uploaded_file = st.file_uploader("è«‹ä¸Šå‚³åœ–ç‰‡ (jpg, png, jpeg)", type=["jpg", "png", "jpeg"])

# é å‚™è®Šæ•¸
image = None
img_tensor = None

if uploaded_file is not None:
    # é¡¯ç¤ºåŸå§‹åœ–ç‰‡
    col1, col2 = st.columns([1, 2])
    with col1:
        st.subheader("ğŸ–¼ï¸ åŸå§‹åœ–ç‰‡")
        image = Image.open(uploaded_file).convert('RGB')
        st.image(image, use_container_width=True)
        
        # æº–å‚™ Tensor çµ¦æ¨¡å‹ç”¨
        img_tensor = transform(image).unsqueeze(0).to(DEVICE)

    with col2:
        # C. å»ºç«‹åˆ†é 
        tab1, tab2 = st.tabs(["ğŸ¨ ç•«å®¶è¾¨è­˜ (Classifier)", "ğŸ” ä»¥åœ–æœåœ– (Image Search)"])

        # === Tab 1: ç•«å®¶è¾¨è­˜ ===
        with tab1:
            st.markdown("#### åˆ†æé€™å¹…ç•«çš„ä½œè€…èˆ‡æµæ´¾")
            
            if st.button("ğŸš€ é–‹å§‹è¾¨è­˜", type="primary", key="btn_classify"):
                with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {model_mode} é€²è¡Œåˆ†æ..."):
                    probs = None
                    if model_mode == "å–®ä¸€æ¨¡å‹ (ResNet50)" and active_model:
                        probs = predict_single(active_model, img_tensor)
                    elif model_mode == "ä¸‰åˆä¸€é›†æˆ (Ensemble)" and ensemble_models:
                        probs = predict_ensemble(ensemble_models, img_tensor)
                    else:
                        st.error("æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œç„¡æ³•é æ¸¬ã€‚")

                    # é¡¯ç¤ºçµæœ
                    if probs is not None:
                        # å–å¾—å‰ 5 å
                        top5_prob, top5_idx = torch.topk(probs, 5)
                        
                        top5_data = []
                        for i in range(5):
                            class_name = class_names[top5_idx[i].item()]
                            probability = top5_prob[i].item()
                            top5_data.append({"ç•«å®¶": class_name, "ä¿¡å¿ƒåº¦": probability})

                        # çµæœæ–‡å­—
                        winner = top5_data[0]
                        st.success(f"ğŸ† é æ¸¬çµæœï¼š**{winner['ç•«å®¶']}** (ä¿¡å¿ƒåº¦: {winner['ä¿¡å¿ƒåº¦']:.1%})")
                        
                        # Altair åœ–è¡¨
                        df = pd.DataFrame(top5_data)
                        chart = alt.Chart(df).mark_bar().encode(
                            x=alt.X('ä¿¡å¿ƒåº¦', axis=alt.Axis(format='%'), scale=alt.Scale(domain=[0, 1])),
                            y=alt.Y('ç•«å®¶', sort='-x'),
                            color=alt.Color('ä¿¡å¿ƒåº¦', scale=alt.Scale(scheme='blues')),
                            tooltip=['ç•«å®¶', alt.Tooltip('ä¿¡å¿ƒåº¦', format='.1%')]
                        ).properties(height=300)
                        
                        st.altair_chart(chart, use_container_width=True)

        # === Tab 2: ä»¥åœ–æœåœ– ===
        with tab2:
            st.markdown("#### å¾ WikiArt è³‡æ–™åº« (80,000+) å°‹æ‰¾ç›¸ä¼¼ç•«ä½œ")
            
            if image_searcher is None:
                st.warning("âš ï¸ æœå°‹è³‡æ–™åº«å°šæœªå»ºç«‹ã€‚è«‹ç¢ºèª `data/processed/` ä¸‹æ˜¯å¦æœ‰ `.npy` æª”æ¡ˆã€‚")
            else:
                if st.button("ğŸ” å°‹æ‰¾ç›¸ä¼¼ç•«ä½œ", key="btn_search"):
                    with st.spinner("æ­£åœ¨æå–ç‰¹å¾µä¸¦æ¯”å° 8 è¬å¼µç•«ä½œ..."):
                        # 1. æå–ç‰¹å¾µ (ä½¿ç”¨ feature_extractor)
                        # æ³¨æ„ï¼šextract æ–¹æ³•é æœŸçš„æ˜¯ PIL Imageï¼Œä¸éœ€è¦è½‰ Tensor
                        query_vec = feature_extractor.extract(image)
                        
                        # 2. åŸ·è¡Œæœå°‹ (æ‰¾ Top 6)
                        results = image_searcher.search(query_vec, k=6)
                    
                    st.success("æœå°‹å®Œæˆï¼ä»¥ä¸‹æ˜¯é¢¨æ ¼æœ€ç›¸è¿‘çš„ç•«ä½œï¼š")
                    
                    # 3. é¡¯ç¤ºçµæœ (3æ¬„ x 2åˆ—)
                    res_cols = st.columns(3)
                    for i, (path, score) in enumerate(results):
                        with res_cols[i % 3]:
                            try:
                                # é¡¯ç¤ºåœ–ç‰‡
                                res_img = Image.open(path)
                                st.image(res_img, use_container_width=True)
                                
                                # è§£ææª”å (å‡è¨­æ ¼å¼: Artist_Name_Title.jpg)
                                file_name = os.path.basename(path)
                                # å˜—è©¦ç°¡å–®åˆ†å‰²ï¼Œå¦‚æœæª”åå¾ˆäº‚ä¹Ÿæ²’é—œä¿‚ï¼Œç›´æ¥é¡¯ç¤ºæª”å
                                caption_txt = f"**Top {i+1}**\n\nç›¸ä¼¼åº¦: {score:.3f}\nğŸ“‚ {file_name}"
                                st.caption(caption_txt)
                                
                            except Exception as e:
                                st.error(f"åœ–ç‰‡è®€å–éŒ¯èª¤: {path}")

else:
    # æ­¡è¿ç•«é¢
    st.info("ğŸ‘ˆ è«‹å¾å·¦å´æˆ–ä¸Šæ–¹ä¸Šå‚³åœ–ç‰‡ä»¥é–‹å§‹åˆ†æ")